{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c08f8277",
   "metadata": {},
   "source": [
    "## Step 1: Setup & Environment Variables\n",
    "\n",
    "Load secrets and configuration from a `.env` file for security and flexibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec32087f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "GRAFANA_API_KEY = os.getenv(\"GRAFANA_API_KEY\")\n",
    "GRAFANA_URL = os.getenv(\"GRAFANA_URL\", \"http://localhost:3000\")\n",
    "PROMETHEUS_UID = os.getenv(\"PROMETHEUS_UID\", \"your_prometheus_uid\")\n",
    "\n",
    "PROMETHEUS_QUERY_ENDPOINT = f\"{GRAFANA_URL}/api/ds/query\"\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {GRAFANA_API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669ec090",
   "metadata": {},
   "source": [
    "## Step 2: LLM Prompt Template (Ollama Llama 3)\n",
    "\n",
    "Generate PromQL from natural language using Llama 3 via Ollama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed54671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: LLM Prompt Template using Ollama Llama 3\n",
    "def generate_promql(natural_query):\n",
    "    prompt = f\"\"\"\n",
    "You are a PromQL expert. Convert the following natural-language query into a valid PromQL expression:\n",
    "Query: \"{natural_query}\"\n",
    "PromQL:\n",
    "\"\"\"\n",
    "    ollama_url = \"http://localhost:11434/api/generate\"\n",
    "    payload = {\n",
    "        \"model\": \"llama3\",\n",
    "        \"prompt\": prompt,\n",
    "        \"options\": {\"num_predict\": 100}\n",
    "    }\n",
    "    llm_output = \"\"\n",
    "    import requests\n",
    "    try:\n",
    "        with requests.post(ollama_url, json=payload, stream=True, timeout=60) as response:\n",
    "            response.raise_for_status()\n",
    "            for line in response.iter_lines():\n",
    "                if line:\n",
    "                    try:\n",
    "                        part = json.loads(line.decode())\n",
    "                        llm_output += part.get(\"response\", \"\")\n",
    "                    except Exception:\n",
    "                        pass\n",
    "    except Exception as e:\n",
    "        print(\"Ollama connection or generation error:\", e)\n",
    "    # Extract PromQL from output\n",
    "    promql_start = llm_output.find('PromQL:')\n",
    "    if promql_start != -1:\n",
    "        promql = llm_output[promql_start + len('PromQL:'):].strip().split('\\n')[0]\n",
    "    else:\n",
    "        promql = llm_output.strip().split('\\n')[0]\n",
    "    return promql"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3738a4b",
   "metadata": {},
   "source": [
    "## Step 3: Query Grafana with PromQL\n",
    "\n",
    "Send the generated PromQL to Grafana using API credentials from `.env`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790d0b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Query Grafana with PromQL\n",
    "def query_grafana(promql, start=\"now-7d\", end=\"now\"):\n",
    "    payload = {\n",
    "        \"queries\": [{\n",
    "            \"refId\": \"A\",\n",
    "            \"datasource\": {\"type\": \"prometheus\", \"uid\": PROMETHEUS_UID},\n",
    "            \"expr\": promql,\n",
    "            \"interval\": \"1m\",\n",
    "            \"format\": \"time_series\",\n",
    "            \"instant\": False\n",
    "        }],\n",
    "        \"range\": {\n",
    "            \"from\": start,\n",
    "            \"to\": end\n",
    "        }\n",
    "    }\n",
    "    response = requests.post(PROMETHEUS_QUERY_ENDPOINT, headers=HEADERS, data=json.dumps(payload))\n",
    "    data = response.json()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3414104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Display Results\n",
    "def display_results(data):\n",
    "    try:\n",
    "        results = data['results']['A']['frames'][0]['data']['values']\n",
    "        timestamps = results[0]\n",
    "        values = results[1]\n",
    "        df = pd.DataFrame({'Time': timestamps, 'Value': values})\n",
    "        display(df)\n",
    "    except Exception as e:\n",
    "        print(\"Error parsing Grafana response:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936b8d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Run Full Flow\n",
    "natural_query = \"Show me last week's error rate\"\n",
    "promql = generate_promql(natural_query)\n",
    "print(\"Generated PromQL:\", promql)\n",
    "\n",
    "grafana_data = query_grafana(promql)\n",
    "display_results(grafana_data)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
